---
title: "New York City AQI Data Exploration"
output: html_notebook
---

### Environment Setup

```{r warning=FALSE}
# Load Libraries
library(RSocrata)
library(aqsr)
library(usethis)
library(devtools)
library(data.table)
library(tidyverse)
library(DataExplorer)
library(filenamer)
library(validate)
library(request)
library(downloader)
```

### Dataset URLs

We have compiled a list of data sets we'd like to explore for this analysis. Each URL contains a query to filter down the records between Jan 1 2018 and Jan 1 2022, and in Manhattan borough or New York county, or New York City.

```{r}
#source("./api/nyc_dataset_urls.R")
```

### Download Data From URLs

Download the URLs onto disk, to avoid storing in R memory. Taxi records are >100+ million, so downloading on disk would be faster. You can see status of download in print comments.

```{r warning=FALSE}
#source("./api/nyc_dataset_downloads.R")
df_list <- readRDS("./api/processed/nyc_dataset_list.csv")
```

### Exploratory Data Analysis

```{r}
# Cleaning functions
medianNA <- function(x){ifelse(is.na(x),
                     median(x, na.rm = TRUE), x)}

meanNA <- function(x){ifelse(is.na(x),
                     mean(x, na.rm = TRUE), x)}
```

In the following script, we do the following:

1. Read downloaded data from JSON into tibble of features stored as tibbles.
2. Create EDA report for each feature tibble using `DataExplorer`.
3. Save EDA reports and tibble of features.

```{r}
#source("./eda/reportdata.R")
features <- readRDS("./data/processed/features.RDS")
tb_features <- tibble(fts = features$df$list[1:nrow(features)])
```

Let's retrieve our constants for the analysis.

```{r}
constants <- readRDS("./api/processed/nyc_constants.csv")
```

**Weather Data**

Cleaning weather data to remove empty columns, and add week #, month, year to dataset.

```{r}
weather <- fread("./data/raw/weather_2018_2022.csv",
                 data.table = TRUE, drop = c("source"))

# Drop all NA columns
weather <- weather %>% discard(~all(is.na(.)))

# Split datetime to retrieve week, month, year
weather$week <- week(weather$datetime)
weather <- separate(weather, "datetime", c("year", "month", "day"), sep = "-")

# Store columns
str_cols <- c("name", "description", "conditions", "latitude", "longitude",
              "day")
store_str <- weather[, .(name, description, conditions, latitude, longitude, day)]

numeric_cols <- setdiff(names(weather), str_cols)

# Extract stations identified by week, year
#stations <- weather[, .(week, year, stations)]

# Fix data types and drop irrelevant columns
weather <- weather[, lapply(.SD, as.numeric), .SDcols = numeric_cols]
weather[, uvindex := NULL]

# Aggregate weather by week
weather %>% group_by(year, week, stations) %>% summarise(n = n())

weather[,nrow := nrow(week), keyby = .(year, week, stations)]

unique(weather)
```


**Air Quality Data**

```{r}
pm25 <- fread("./data/raw/new-york, usa-air-quality.csv",
                 data.table = TRUE)

# Drop columns with more than 30% total NA values
cols <- profile_missing(pm25) %>% filter(pct_missing > 0.30)
pm25[, as.character(cols$feature) := NULL]

# Split datetime to retrieve week, month, year
pm25[, week := week(date)]
pm25 <- separate(pm25, "date", c("year", "month", "day"),
                 sep = "/") 
# Fix data types 
pm25[,lapply(.SD, as.integer),.SDcols = c("year", "month", "day")]
pm25[,pm25 := as.numeric(pm25)]

# Select rows by temporal var
pm25 <- pm25[year %between% list(year(constants$TIME_START), year(constants$TIME_END))]

pm25 <- pm25[, lapply(.SD, medianNA), .SDcols = c("pm25"), by = .(week, month, year)]

pm25 <- pm25 %>% group_by(week, month, year) %>% 
              summarise(avg_pm25 = mean(pm25), n = n())

fwrite(pm25, "./data/processed/pm25.RDS", col.names = TRUE)
#fwrite(weather, "./data/processed/weather.RDS", col.names = TRUE)
```

Combine *weather* and *PM2.5* datasets.

```{r}
nrow(pm25)
nrow(weather)
```

```{r}
features <- profile_missing(data) %>% filter(pct_missing < 0.35)
features$feature
```

### AQI Data
```{r}
aqi_pollutants <- aqs_list_parameters(aqs_user, pc="AQI POLLUTANTS")
aqi_forecast <- aqs_list_parameters(aqs_user, pc="FORECAST")
```

```{r}
s2 <- aqs_dailyData(aqs_user=aqs_user,
                     endpoint="byCounty",
                     state=ny_fips_code,
                     county=nyCounty_fips_code,
                     bdate="20160101",
                     edate="20161231",
                     param=aqi_pollutants$code[1])
```

### Road Networks 
```{r}
# Read this shape file with the rgdal library. 
library(rgdal)

my_spdf <- readOGR( 
  dsn= paste0(getwd(), "/data/citymap_citymap_v1") , 
  layer="citymap_citymap_v1",
  verbose=FALSE)
```

```{r}
# Basic plot of this shape file:
par(mar=c(0,0,0,0))
plot(my_spdf, col="#f2f2f2", bg="black", lwd=0.25 )
```

```{r}
head(my_spdf)
```

```{r}
nyC_map <- my_spdf[my_spdf$boro_nm == BOROUGH]

is_(my_spdf$boro_nm == BOROUGH )

str(my_spdf)

names(my_spdf)

unique(my_spdf$ownership_)

my_spdf
```


```{r}
# Basic plot of this shape file:
par(mar=c(0,0,0,0))
plot(nyC_map, col="#f2f2f2", bg="black", lwd=0.25 )
```
