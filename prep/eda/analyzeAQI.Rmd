---
title: "New York City AQI Data Exploration"
output: html_notebook
---

### Environment Setup

```{r output=FALSE}
# Load Libraries
library(usethis)
library(devtools)
library(data.table)
library(tidyverse)
library(DataExplorer)
library(stringi)
library(jsonlite)
# library(filenamer)
```

### Dataset URLs

We have compiled a list of data sets we'd like to explore for this analysis. Each URL contains a query to filter down the records between Jan 1 2018 and Jan 1 2022, and in Manhattan borough or New York county, or New York City.

```{r}
#source("./api/nyc_dataset_urls.R")
```

### Download Data From URLs

Download the URLs onto disk, to avoid storing in R memory. Taxi records are >100+ million, so downloading on disk would be faster. You can see status of download in print comments.

```{r warning=FALSE}
#source("./api/nyc_dataset_downloads.R")
df_list <- readRDS("./api/processed/nyc_dataset_list.csv")
```

### Exploratory Data Analysis

```{r}
# Cleaning functions
medianNA <- function(x){ifelse(is.na(x),
                     median(x, na.rm = TRUE), x)}

meanNA <- function(x){ifelse(is.na(x),
                     mean(x, na.rm = TRUE), x)}

cleanString2Num <- function(mystring) {
}

```

In the following script, we do the following:

1. Read downloaded data from JSON into tibble of features stored as tibbles.
2. Create EDA report for each feature tibble using `DataExplorer`.
3. Save EDA reports and tibble of features.

```{r}
#source("./eda/reportdata.R")
features <- readRDS("./data/processed/features.RDS")
tb_features <- tibble(fts = features$df$list[1:nrow(features)])
```

Let's retrieve our constants for the analysis.

```{r}
constants <- readRDS("./api/processed/nyc_constants.csv")
identifiers <- readRDS("./api/processed/nyc_identifiers.csv")
```

**Air Quality Data**

Cleaning air quality (pm2.5) data to remove empty columns, and add week #, month, year to dataset.

```{r output = FALSE}
pm25 <- fread("./data/raw/new-york, usa-air-quality.csv",
                 data.table = TRUE)

# Drop columns with more than 30% total NA values
cols <- profile_missing(pm25) %>% filter(pct_missing > 0.30)
pm25[, as.character(cols$feature) := NULL]

# Split datetime to retrieve week, month, year
pm25[, week := week(date)]
pm25 <- separate(pm25, "date", c("year", "month", "day"),
                 sep = "/") 
# Fix data types 
pm25[, `:=` (year = as.integer(year), month = as.integer(month), day = as.integer(day))]
pm25[,pm25 := as.numeric(pm25)]

# Select rows by temporal var
pm25 <- pm25[year %between% list(year(constants$TIME_START),
                                 year(constants$TIME_END) - 1)]

# Fill NA with median
pm25 <- pm25[, lapply(.SD, medianNA), .SDcols = c("pm25"), by = .(year,month,week)]

# Extract week, month, year for temporal
temporal <- pm25 %>% group_by(year,month, week) %>% 
              summarise(n = n()) %>% data.table()

fwrite(temporal, "./data/processed/temporal.csv", col.names = TRUE)

# Get weekly pm25 data
pm25 <- pm25 %>% group_by(year,week) %>% 
              summarise(pm25 = mean(pm25)) %>% data.table()

fwrite(pm25, "./data/processed/pm25.csv", col.names = TRUE)
```


**Weather Data**

Cleaning weather data to remove empty columns, and add week #, month, year to dataset.

```{r}
weather <- fread("./data/raw/weather_2018_2022.csv",
                 data.table = TRUE, drop = c("source"))
```

```{r warning=FALSE}
# Split datetime into week, month, year
weather$week <- week(weather$datetime)
weather <- separate(weather, "datetime", c("year", "month", "day"), sep = "-")

# Split datetime into primary and secondary conditions
weather <- separate(weather, "conditions", 
                    c("primarycondition", 
                      "secondarycondition"), 
                    sep = ", ")
# Fill NAs for new columns
weather[is.na(secondarycondition), ]$secondarycondition <- "None"
```

```{r}
# Select rows by temporal var
weather <- weather[year < year(constants$TIME_END)]

# Fix data types
weather[, `:=`(year = as.integer(year), 
               month = as.integer(month), 
               week = as.integer(week))]

# Drop all NA and irrelevant columns 
weather <- weather %>% discard(~all(is.na(.))) 
weather[, day := NULL]
weather[, uvindex := NULL]

# Select useful numeric data
store <- weather[,.(year, week, name, latitude, longitude, description, stations)]

use <- setdiff(names(weather), c("name", "latitude",
                                 "longitude", "description",
                                 "stations", "month"))
weather <- weather %>% select(use)

# Fill NAs with median of (week, year)
weather <- weather[, lapply(.SD, medianNA), 
                   .SDcols = setdiff(use,c("year", "week")), 
                   by = .(year, week)]

# Missing data : windgust
profile_missing(weather) %>% filter(pct_missing > 0)

# Fill NA of missing (week, year) with median of (week-1, year)
weather[is.na(windgust),]$windgust <- weather[year == weather[is.na(windgust),]$year[1]][week == weather[is.na(windgust),]$week[1] - 1][, windgust] %>% median()
```

```{r}
### WE DID NOT INCLUDE THESE COLUMNS IN THE FINAL PM25 DATASET ###

# Convert conditions to factors
weather[,`:=`(primarycondition = as.factor(primarycondition), secondarycondition = as.factor(secondarycondition))]

weather_factors <- stack(data.frame("Clear" = 1, 
                                    "Partially cloudy" = 2,"Overcast" = 3,
                                    "Rain" = 4, "Snow" = 5, "None" = 0))

# Save weather factor codes for future reference
saveRDS(weather_factors, "./data/processed/weather_factors.csv")

# Map factors to codes
weather$primarycondition <- weather$primarycondition %>% 
                              recode_factor("Clear" = 1, 
                                            "Partially cloudy" = 2,
                                            "Overcast" = 3, 
                                            "Rain" = 4, "Snow" = 5, 
                                            "None" = 0)

weather$secondarycondition <- weather$secondarycondition %>% 
                              recode_factor("Clear" = 1, 
                                            "Partially cloudy" = 2,
                                            "Overcast" = 3, 
                                            "Rain" = 4, "Snow" = 5, 
                                            "None" = 0)
```

```{r}
# Get weekly weather data
weather <- weather[,lapply(.SD, mean), 
                   .SDcols = setdiff(use,c("year", "week",
                                           "primarycondition",
                                           "secondarycondition")), by = .(year, week)]
# Save weather data
fwrite(weather, "./data/processed/weather.csv")

weather
```


**Debugging**

Problem : Same week repeating for different months, because week is parsed from datetime. 

What I want: Map week to months to merge monthly data with weekly data. 

```{r}
# save temporal vars
temporal <- fread("./data/processed/temporal.csv")
```

We need around 212 - 243 rows in the merged dataset.

```{r}
# Read data
taxi_monthly <- fread("./data/raw/taxi/data_reports_monthly.csv", data.table = TRUE)

# Split datetime to retrieve week, month, year
taxi_monthly <- separate(taxi_monthly, "Month/Year", c("year", "month"), sep = "-") 

# Fix data types 
taxi_monthly[, `:=`(year = as.integer(year), month = as.integer(month))]

# Select rows by temporal var
taxi_monthly <- taxi_monthly[year %between% list(year(constants$TIME_START),year(constants$TIME_END) - 1)]

# Sort temporal and taxi_monthly BOTH by (year, month)
taxi_monthly <- taxi_monthly %>% group_by(month, year) %>% arrange(year, month)
```

```{r}
# Merge datasets to get (54 * 4 * 6) rows + (54*3) repeating rows
merge <- merge(taxi_monthly, temporal, sort = FALSE) %>% data.table() # 1458 rows

# Remove month and n
merge <- merge[, c("month", "n") := NULL]
```

*PROBLEM FIXED:* We aggregate data into *1458 rows*, pending merge for duplicated weekly but distinct month values. 


**Taxi Weekly Data**

Cleaning weekly taxi data to remove empty columns, and fix datatypes.

```{r}
# Assign merged dataset as weekly taxi data
taxi_weekly <- merge

# Remove NA and irrelevant columns
taxi_weekly[taxi_weekly == '-'] <- NA

# Drop columns with more than 30% total NA values
cols <- profile_missing(taxi_weekly) %>% filter(pct_missing < 0.30)
taxi_weekly <- taxi_weekly %>% select(cols$feature) %>% tibble() %>% relocate(week, .after = year) # change week column's location

# Fix data types
taxi_weekly <- data.table(taxi_weekly)[,by = .(year, week, `License Class`)]

t <- taxi_weekly[,lapply(.SD, function(x)str_replace_all(x,"[^[:alnum:]]", "") %>% as.integer()),.SDcols = c("Trips Per Day", "Unique Drivers",
                              "Unique Vehicles" , "Vehicles Per Day",
                        "Avg Minutes Per Trip"), 
                 by = .(year, week, `License Class`)]

taxi_weekly <- taxi_weekly %>% arrange(year,week)
t <- t %>% arrange(year, week)

# Cleanup columns in strings to numbers
taxi_weekly$`Trips Per Day` <- t$`Trips Per Day`
taxi_weekly$`Unique Drivers` <- t$`Unique Drivers`
taxi_weekly$`Unique Vehicles` <- t$`Unique Vehicles`
taxi_weekly$`Avg Minutes Per Trip` <- t$`Avg Minutes Per Trip`
taxi_weekly$`Vehicles Per Day` <- t$`Vehicles Per Day`
taxi_weekly

# Columns that should be whole numbers only
int_cols <- c("Trips Per Day", "Unique Drivers", "Unique Vehicles", "Avg Minutes Per Trip", "Vehicles Per Day")
```

```{r}
# Combine data for same weeks data but in different months 
# by taking mean between the pairs of 2 rows.
taxi_weekly <- taxi_weekly[, lapply(.SD, function(x)round(mean(x),1)), 
            by = .(year, week, `License Class`)]

# Fix data types
taxi_weekly[, `:=`(`Trips Per Day` = as.integer(`Trips Per Day`),
                    `Unique Drivers` = as.integer(`Unique Drivers`),
                    `Unique Vehicles` = as.integer(`Unique Vehicles`),
                    `Avg Minutes Per Trip` = as.integer(`Avg Minutes Per Trip`), 
                     `Vehicles Per Day` = as.integer(`Vehicles Per Day`))]

# Save weekly taxi data
fwrite(taxi_weekly, "./data/processed/taxi_weekly.csv")
```

**Gas and Diesel Retail Prices**

Let's clean up and prepare weekly Gas Retail Prices. 

```{r}
# Read data
gasRetailPrice <- tb_features$fts[6][[1]] # 6

# Select relevant columns
gasRetailPrice <- gasRetailPrice %>% select(date, new_york_city_average_gal) %>% data.table()

# Split datetime to retrieve week, month, year
gasRetailPrice$week <- week(gasRetailPrice$date)
gasRetailPrice <- separate(gasRetailPrice, "date", c("year", "month", "day"), sep = "-") 

# Fix data types and discard irrelvant columns
gasRetailPrice <- gasRetailPrice[, c("month", "day") := NULL] %>% tibble() %>% relocate(week, .after = year) %>% data.table()

gasRetailPrice[, `:=` (new_york_city_gas_average_gal = as.numeric(new_york_city_average_gal), 
                       year = as.integer(year))]

gasRetailPrice[, new_york_city_average_gal := NULL]

# Week 1 2019 data is missing, added mean of week before and after

week1_gasRetailPrice <- data.frame(year = as.integer(2019), 
                                   week = as.integer(1), 
                                   new_york_city_gas_average_gal =                         as.numeric(mean(c(gasRetailPrice[year == 2018][week == 53]$new_york_city_gas_average_gal, gasRetailPrice[year == 2019][week == 2]$new_york_city_gas_average_gal))))

# week 42
week42_gasRetailPrice <- data.frame(year = as.integer(2019), 
                                      week = as.integer(42), 
                        new_york_city_gas_average_gal = 
                          as.numeric(mean(c(gasRetailPrice[year == 2019][week == 40]$new_york_city_gas_average_gal,gasRetailPrice[year == 2019][week == 41]$new_york_city_gas_average_gal))))

# week 43
week43_gasRetailPrice <- data.frame(year = as.integer(2019), 
                                      week = as.integer(43), 
                        new_york_city_gas_average_gal = 
                          as.numeric(mean(c(gasRetailPrice[year == 2019][week == 41]$new_york_city_gas_average_gal,gasRetailPrice[year == 2019][week == 42]$new_york_city_gas_average_gal))))

# week 44
week44_gasRetailPrice <- data.frame(year = as.integer(2019), 
                                      week = as.integer(44), 
                        new_york_city_gas_average_gal = 
                          as.numeric(mean(c(gasRetailPrice[year == 2019][week == 42]$new_york_city_gas_average_gal,gasRetailPrice[year == 2019][week == 43]$new_york_city_gas_average_gal))))

# 2020 Week 53
week53_20_gasRetailPrice <- data.frame(year = as.integer(2020), 
                                      week = as.integer(53), 
                        new_york_city_gas_average_gal = 
                          as.numeric(mean(c(gasRetailPrice[year == 2020][week == 51]$new_york_city_gas_average_gal,gasRetailPrice[year == 2020][week == 52]$new_york_city_gas_average_gal))))

gasRetailPrice <- rbind(gasRetailPrice, week1_gasRetailPrice, week42_gasRetailPrice, week43_gasRetailPrice, week44_gasRetailPrice) %>% arrange(year, week) %>% data.table()

# 2021 Week 53
week53_21_gasRetailPrice <- data.frame(year = as.integer(2021), 
                                      week = as.integer(53), 
                        new_york_city_gas_average_gal = 
                          as.numeric(mean(c(gasRetailPrice[year == 2021][week == 51]$new_york_city_gas_average_gal,gasRetailPrice[year == 2021][week == 52]$new_york_city_gas_average_gal))))

gasRetailPrice <- rbind(gasRetailPrice, week42_gasRetailPrice, 
                        week43_gasRetailPrice, week44_gasRetailPrice, week53_21_gasRetailPrice,
                        week53_20_gasRetailPrice) %>% arrange(year, week) %>% data.table()

dieselRetailPrice
# Save data
fwrite(gasRetailPrice, "./data/processed/gasRetailPrice.csv")
```

Now let's clean up and prepare weekly Diesel Retail Prices. 

```{r}
# Read data
dieselRetailPrice <- tb_features$fts[5][[1]] # 5

# Select relevant columns
dieselRetailPrice <- dieselRetailPrice %>% select(date, new_york_city_average_gal) %>% data.table()

# Split datetime to retrieve week, month, year
dieselRetailPrice$week <- week(dieselRetailPrice$date)
dieselRetailPrice <- separate(dieselRetailPrice, "date", c("year", "month", "day"), sep = "-") 

# Fix data types and discard irrelevant columns
dieselRetailPrice <- dieselRetailPrice[, c("month", "day") := NULL] %>% tibble() %>% relocate(week, .after = year) %>% data.table()

dieselRetailPrice[, `:=` (new_york_city_diesel_average_gal  = as.numeric(new_york_city_average_gal), year = as.integer(year))]

dieselRetailPrice[, new_york_city_average_gal := NULL]

# Week 1 2019 data is missing, added mean of week before and after
week1_dieselRetailPrice <- data.frame(year = as.integer(2019), 
                                      week = as.integer(1), 
                        new_york_city_diesel_average_gal = 
                          as.numeric(mean(c(dieselRetailPrice[year == 2018][week == 53]$new_york_city_diesel_average_gal,dieselRetailPrice[year == 2019][week == 2]$new_york_city_diesel_average_gal))))

week42_dieselRetailPrice <- data.frame(year = as.integer(2019), 
                                      week = as.integer(42), 
                        new_york_city_diesel_average_gal = 
                          as.numeric(mean(c(dieselRetailPrice[year == 2019][week == 40]$new_york_city_diesel_average_gal,dieselRetailPrice[year == 2019][week == 41]$new_york_city_diesel_average_gal))))

week43_dieselRetailPrice <- data.frame(year = as.integer(2019), 
                                      week = as.integer(43), 
                        new_york_city_diesel_average_gal = 
                          as.numeric(mean(c(dieselRetailPrice[year == 2019][week == 41]$new_york_city_diesel_average_gal,dieselRetailPrice[year == 2019][week == 42]$new_york_city_diesel_average_gal))))

week44_dieselRetailPrice <- data.frame(year = as.integer(2019), 
                                      week = as.integer(44), 
                        new_york_city_diesel_average_gal = 
                          as.numeric(mean(c(dieselRetailPrice[year == 2019][week == 42]$new_york_city_diesel_average_gal,dieselRetailPrice[year == 2019][week == 43]$new_york_city_diesel_average_gal))))

# 2020 Week 53 
week53_20_dieselRetailPrice <- data.frame(year = as.integer(2020), 
                                      week = as.integer(53), 
                        new_york_city_diesel_average_gal = 
                          as.numeric(mean(c(dieselRetailPrice[year == 2020][week == 51]$new_york_city_diesel_average_gal,dieselRetailPrice[year == 2020][week == 52]$new_york_city_diesel_average_gal))))

# 2021 Week 53
week53_21_dieselRetailPrice <- data.frame(year = as.integer(2021), 
                                      week = as.integer(53), 
                        new_york_city_diesel_average_gal = 
                          as.numeric(mean(c(dieselRetailPrice[year == 2021][week == 51]$new_york_city_diesel_average_gal,dieselRetailPrice[year == 2021][week == 52]$new_york_city_diesel_average_gal))))

# Combine missing data
dieselRetailPrice <- rbind(dieselRetailPrice, week1_dieselRetailPrice, week42_dieselRetailPrice,
                           week43_dieselRetailPrice, week44_dieselRetailPrice, 
                           week53_20_dieselRetailPrice, week53_21_dieselRetailPrice) %>% arrange(year, week) %>% data.table()

dieselRetailPrice

# Save data
fwrite(dieselRetailPrice, "./data/processed/dieselRetailPrice.csv")
```

```{r}
motorCrashes <- tb_features$fts[9][[1]]  %>% data.table()# 9
motorCrashes

# Split datetime to retrieve week, month, year
motorCrashes$week <- week(motorCrashes$crash_date)
motorCrashes <- separate(motorCrashes, "crash_date", c("year", "month"), sep = "-") 

# Fix data types 
motorCrashes[, `:=`(year = as.integer(year), month = as.integer(month), week = as.integer(week))]

# Drop irrelevant columns
cols <- profile_missing(motorCrashes) %>% filter(pct_missing > 0.20)
motorCrashes[, as.character(cols$feature) := NULL]

motorCrashes[, c("number_of_persons_injured", "number_of_persons_killed", "number_of_pedestrians_injured", "number_of_pedestrians_killed", "number_of_cyclist_injured", "number_of_cyclist_killed", "number_of_motorist_injured", "number_of_motorist_killed", "borough", "zip_code", "collision_id", "vehicle_type_code1", "crash_time", "location.latitude", "location.longitude") := NULL]
```

```{r}
# ONLY 2018 and 2019 data here
# busCustomerJourneyMetricsMTA <- tb_features$fts[3][[1]]
# 
# # Split datetime to retrieve week, month, year
# busCustomerJourneyMetricsMTA <- separate(busCustomerJourneyMetricsMTA, "month", c("year", "month"), sep = "-")  %>% data.table()
# 
# period <- busCustomerJourneyMetricsMTA$period
# 
# busCustomerJourneyMetricsMTA
# 
# busCustomerJourneyMetricsMTA[, c("trip_type", "borough", "route_id", "period") := NULL]
# busCustomerJourneyMetricsMTA
# 
# unique(busCustomerJourneyMetricsMTA$year)
```



**Electricity Consumption**

```{r}
electricityGenerated <- fread("./data/raw/Net_generation_for_all_sectors.csv")

# YYYYMM
names(electricityGenerated)
eng <- electricityGenerated %>% data.frame() %>% stack() 


electricityGenerated <- electricityGenerated %>% select(-c("units", "source key")) %>% data.table()

electricityGenerated[2:6]

electricityGenerated$description

names <- c("monthlyElectricUtility", "monthlyIndependentPowerProducers", "monthlyCommercial_NetGen", "monthlyIndustrial_NetGen", "monthlyAllSectors_NetGen" )
```

```{r}
# Split datetime into week, month, year
# energyConsumptionAll$week <- week(energyConsumptionAll$YYYYMM)

electricityGenerated$year <- substr(electricityGenerated$YYYYMM, 0,4) %>% as.integer()

electricityGenerated$month <- substr(electricityGenerated$YYYYMM, 5,6) %>% as.integer()


unique(electricityGenerated$month)


electricityGenerated %>% create_report() %>% try(TRUE)
```



### Combining Datasets

1. Combine *weather*, **taxi_weekly**, **gas retail prices**, **diesel retail prices** and *PM2.5* datasets into *master*.

```{r}
## WE MERGE TO GET DATA FOR 209 WEEKS
# Read Data
pm25 <- fread("./data/processed/pm25.csv")
weather <- fread("./data/processed/weather.csv")
taxi_weekly <- fread("./data/processed/taxi_weekly.csv")
gasRetailPrice <- fread("./data/processed/gasRetailPrice.csv")
dieselRetailPrice <- fread("./data/processed/dieselRetailPrice.csv")

# Set keys
setkey(pm25, year, week)
setkey(weather, year, week)
setkey(taxi_weekly, year, week, `License Class`)
setkey(gasRetailPrice, year, week)
setkey(dieselRetailPrice, year, week)

# Merge
master <- weather[pm25]
master <- gasRetailPrice[master]
master <- dieselRetailPrice[master]
master <- master[taxi_weekly]

master <- master %>% tibble() %>% relocate(pm25, .after = ncol(master)) %>% data.table()

View(master)
sum(is.na(master))
# Save master data
fwrite(master, "./data/processed/master_1.csv")
```


### Road Networks 
```{r}
# Read this shape file with the rgdal library. 
library(rgdal)

my_spdf <- readOGR( 
  dsn= paste0(getwd(), "/data/citymap_citymap_v1") , 
  layer="citymap_citymap_v1",
  verbose=FALSE)
```

```{r}
# Basic plot of this shape file:
par(mar=c(0,0,0,0))
plot(my_spdf, col="#f2f2f2", bg="black", lwd=0.25 )
```

```{r}
head(my_spdf)
```

```{r}
nyC_map <- my_spdf[my_spdf$boro_nm == BOROUGH]

is_(my_spdf$boro_nm == BOROUGH )

str(my_spdf)

names(my_spdf)

unique(my_spdf$ownership_)

my_spdf

# Fix Data Types
# taxi_weekly[, `:=`("`Trips Per Day`" = as.integer("`Trips Per Day`"))]
# 
#           "Unique Drivers"= as.integer("Unique Drivers"),
#            "Unique Vehicles" = as.integer("Unique Vehicles"),
#           "Vehicles Per Day" = as.integer("Vehicles Per Day"),
#           "Avg Minutes Per Trip" = as.numeric("Avg Minutes Per Trip"))]
```


```{r}
# Basic plot of this shape file:
par(mar=c(0,0,0,0))
plot(nyC_map, col="#f2f2f2", bg="black", lwd=0.25 )
```
